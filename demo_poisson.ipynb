{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "r\"\"\"\n",
    "Self-supervised learning with Generalized Recorrupted-to-Recovered (GR2R) \n",
    "====================================================================================================\n",
    "\n",
    "This example shows you how to train a reconstruction network for an denoising problem on a fully self-supervised way, i.e., using corrupted measurement data only.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import deepinv as dinv\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from deepinv.optim.prior import PnP\n",
    "from deepinv.utils.demo import load_dataset, load_degradation\n",
    "import wandb\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from deepinv.loss import PSNR, SSIM, Loss, SupLoss\n",
    "\n",
    "from deepinv.training import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    batch_size  = 20\n",
    "    loss        = \"sup\"\n",
    "    epochs      = 100\n",
    "    lr          = 1e-4\n",
    "    noise       = 0.1\n",
    "    trial       = 0\n",
    "    alpha       = 0.2\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected GPU 0 with 23177 MB free memory \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------------\n",
    "# Setup paths for data loading and results.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "BASE_DIR = Path(\".\")\n",
    "# PROJECT_NAME = \"denoising-poisson\"\n",
    "PROJECT_NAME = \"denoising-poisson\"\n",
    "ORIGINAL_DATA_DIR =  Path(\"./data\")\n",
    "DATA_DIR = ORIGINAL_DATA_DIR / \"measurements\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "DEG_DIR = BASE_DIR / \"degradations\"\n",
    "CKPT_DIR = BASE_DIR / \"ckpts\" / PROJECT_NAME\n",
    "verbose   = True\n",
    "wandb_vis = False\n",
    "\n",
    "# Set the global random seed from pytorch to ensure reproducibility of the example.\n",
    "device = dinv.utils.get_freer_gpu() if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args object at 0x7efbe5272d00>\n"
     ]
    }
   ],
   "source": [
    "# print  all the arguments\n",
    "print(args)\n",
    "\n",
    "trial_id = args.trial\n",
    "torch.manual_seed(trial_id)\n",
    "\n",
    "run_name = f\"{args.loss}-{args.noise}\"\n",
    "\n",
    "wandb_setup = {\n",
    "    \"project\": PROJECT_NAME,\n",
    "    \"config\": args,\n",
    "    \"name\": run_name,\n",
    "}\n",
    "\n",
    "operation = f\"Denoising_{args.noise}\"\n",
    "train_dataset_name = \"div2k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----------------------------------------------------------------------------------\n",
    "# Generate a dataset of knee images and load it.\n",
    "# ----------------------------------------------------------------------------------\n",
    "\n",
    "# mask = load_degradation(\"mri_mask_128x128.npy\", ORIGINAL_DATA_DIR)\n",
    "\n",
    "# defined physics\n",
    "# physics = dinv.physics.MRI(mask=mask, device=device, noise_model=dinv.physics.GaussianNoise(args.noise) )\n",
    "physics = dinv.physics.Denoising(noise_model=dinv.physics.PoissonNoise(args.noise))\n",
    "\n",
    "# Use parallel dataloader if using a GPU to fasten training,\n",
    "# otherwise, as all computes are on CPU, use synchronous data loading.\n",
    "num_workers = 0 if torch.cuda.is_available() else 0\n",
    "n_images_max = 100\n",
    "\n",
    "my_dataset_name = \"div2k_poisson\"\n",
    "measurement_dir = DATA_DIR / train_dataset_name / operation\n",
    "\n",
    "# check if the dataset is already generated\n",
    "# if not, generate it\n",
    "if not os.path.exists(measurement_dir / f\"{my_dataset_name}0.h5\"):\n",
    "\n",
    "    img_size = 224\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomCrop((img_size, img_size))\n",
    "        ])\n",
    "    \n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.CenterCrop((512, 512))\n",
    "    ])\n",
    "\n",
    "    train_dataset    =  dinv.datasets.DIV2K(root=ORIGINAL_DATA_DIR, mode=\"train\", transform=transform, download=True)\n",
    "    test_dataset     =  dinv.datasets.DIV2K(root=ORIGINAL_DATA_DIR, mode=\"val\", transform=test_transform, download=True)\n",
    "\n",
    "    deepinv_datasets_path = dinv.datasets.generate_dataset(\n",
    "        train_dataset=train_dataset,\n",
    "        test_dataset=test_dataset,\n",
    "        physics=physics,\n",
    "        device=device,\n",
    "        save_dir=measurement_dir,\n",
    "        train_datapoints=n_images_max,\n",
    "        num_workers=num_workers,\n",
    "        dataset_filename=str(my_dataset_name),\n",
    "    )\n",
    "\n",
    "else:      \n",
    "    deepinv_datasets_path = measurement_dir / f\"{my_dataset_name}0.h5\"\n",
    "\n",
    "train_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=True)\n",
    "test_dataset = dinv.datasets.HDF5Dataset(path=deepinv_datasets_path, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the reconstruction network\n",
    "# ---------------------------------------------------------------\n",
    "#\n",
    "# As a reconstruction network, we use an unrolled network (half-quadratic splitting)\n",
    "# with a trainable denoising prior based on the DnCNN architecture.\n",
    "\n",
    "n_channels = 3  \n",
    "\n",
    "\n",
    "model = dinv.models.DRUNet( in_channels=n_channels,\n",
    "                            out_channels=n_channels,\n",
    "                            pretrained=None,\n",
    "                            nc=[16, 32, 64, 128],\n",
    "                            train=True,\n",
    "                            last_act='relu').to(device)\n",
    "\n",
    "# print number of parameters\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "\n",
    "# Set up the training parameters\n",
    "# --------------------------------------------\n",
    "\n",
    "epochs        = args.epochs\n",
    "learning_rate = args.lr\n",
    "batch_size    = args.batch_size # if torch.cuda.is_available() else 1\n",
    "noise_level   = args.noise\n",
    "\n",
    "\n",
    "if args.loss == \"sup\":   # SUPERVISED LOSS\n",
    "    loss = dinv.loss.SupLoss()\n",
    "\n",
    "elif args.loss == \"er\": # GENERALIZED R2R LOSS - NLL VARIANT\n",
    "\n",
    "    def poisson_nll_loss(y_pred, y_true):\n",
    "        return torch.nn.functional.poisson_nll_loss(y_pred / noise_level, \n",
    "                                                    y_true / noise_level,  \n",
    "                                                    log_input=False, \n",
    "                                                    full=False, \n",
    "                                                    eps=1e-4)        \n",
    "\n",
    "    r2r_loss = dinv.loss.R2RPoissonLoss(metric=poisson_nll_loss, gain=noise_level, p=0.1)\n",
    "    loss     = [ r2r_loss ]\n",
    "    model    = r2r_loss.adapt_model(model)\n",
    "\n",
    "elif args.loss == \"er_mse\": # GENERALIZED R2R LOSS - MSE VARIANT\n",
    "\n",
    "    r2r_loss = dinv.loss.R2RPoissonLoss(metric=torch.nn.MSELoss(), gain=noise_level, p=args.alpha)\n",
    "    loss     = [ r2r_loss ]\n",
    "    model    = r2r_loss.adapt_model(model, MC_samples=10)\n",
    "\n",
    "elif args.loss == \"neigh\": # NEIGHBORHOOD LOSS\n",
    "\n",
    "    neigh_loss = dinv.loss.Neighbor2Neighbor()\n",
    "    loss = [ neigh_loss ]\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=int(epochs * 0.8) + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=1, num_workers=num_workers, shuffle=False\n",
    ")\n",
    "\n",
    "trainer = dinv.Trainer(\n",
    "    metrics=[ PSNR(), SSIM() ],\n",
    "    model=model,\n",
    "    physics=physics,\n",
    "    epochs=epochs,\n",
    "    scheduler=scheduler,\n",
    "    losses=loss,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    plot_images=True,\n",
    "    device=device,\n",
    "    save_path=Path(CKPT_DIR / f\"noise={args.noise}\"  / args.loss ),\n",
    "    verbose=verbose,\n",
    "    wandb_vis=False,\n",
    "    show_progress_bar=True,\n",
    "    ckp_interval=1,\n",
    "    wandb_setup=None,\n",
    "    eval_dataloader=test_dataloader,\n",
    "    freq_plot=10,\n",
    ")\n",
    "\n",
    "model = trainer.train()\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "print(\"EVALUATING THE MODEL ON THE TEST DATASET\")\n",
    "trainer.test(test_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepinv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
